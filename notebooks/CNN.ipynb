{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "epoches = 2\n",
    "batch_size = 1;\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = \"./mnist/\",\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.ToTensor(),\n",
    "    download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data.train_data.size())\n",
    "plt.imshow(train_data.train_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./mnist/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(root = \"./mnist\", train = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.unsqueeze(test_data.test_data, dim = 1).type(torch.FloatTensor) / 255\n",
    "test_y = test_data.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
       "          0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
       "          0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
       "          0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
       "          0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
       "          0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
       "          0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "          0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
       "          0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
       "          0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
       "          0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
       "          0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 1,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.FC = nn.Linear(in_features = 13 * 13 * 8, out_features = 10)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        output = self.FC(x)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 1,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.FC = nn.Linear(in_features = 13 * 13 * 8, out_features = 10)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        \n",
    "        output = self.FC(output)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ViewBackward>)\n",
      "7\n",
      "tensor([7])\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "# load parameters\n",
    "cnn.load_state_dict(torch.load(\"../model/cnn.pth\"))\n",
    "\n",
    "test_output = cnn(test_x[:1])\n",
    "#print(test_output)\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y)\n",
    "print(test_y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "test_cnn = test()\n",
    "# load parameters\n",
    "test_cnn.load_state_dict(torch.load(\"../model/cnn.pth\"), strict = False)\n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "    for e in batch_x:\n",
    "        print(e)\n",
    "\n",
    "    test_output = test_cnn(batch_x)\n",
    "\n",
    "    cpt_path = '../data/check_file/'\n",
    "    check_file = torch.flatten(test_output).detach().numpy()\n",
    "    name = 'test_fc_output'\n",
    "    with open(cpt_path + str(name), 'w') as f:\n",
    "        for output in check_file:\n",
    "            f.write(str(output) + ' ')\n",
    "        \n",
    "    break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing epoch 0...\n",
      "Epoch:  0 | train loss: 2.8107 | test accuract: 0.12\n",
      "Epoch:  0 | train loss: 3.2033 | test accuract: 0.50\n",
      "Epoch:  0 | train loss: 1.0116 | test accuract: 0.70\n",
      "Epoch:  0 | train loss: 1.6957 | test accuract: 0.72\n",
      "Epoch:  0 | train loss: 0.0156 | test accuract: 0.75\n",
      "Epoch:  0 | train loss: 3.8055 | test accuract: 0.73\n",
      "Epoch:  0 | train loss: 0.1636 | test accuract: 0.82\n",
      "Epoch:  0 | train loss: 0.1390 | test accuract: 0.81\n",
      "Epoch:  0 | train loss: 0.0626 | test accuract: 0.80\n",
      "Epoch:  0 | train loss: 0.4805 | test accuract: 0.85\n",
      "Epoch:  0 | train loss: 0.0429 | test accuract: 0.84\n",
      "Epoch:  0 | train loss: 0.2408 | test accuract: 0.85\n",
      "Epoch:  0 | train loss: 0.0522 | test accuract: 0.81\n",
      "Epoch:  0 | train loss: 0.1553 | test accuract: 0.84\n",
      "Epoch:  0 | train loss: 0.0713 | test accuract: 0.84\n",
      "Epoch:  0 | train loss: 0.4692 | test accuract: 0.86\n",
      "Epoch:  0 | train loss: 1.6705 | test accuract: 0.87\n",
      "Epoch:  0 | train loss: 0.0246 | test accuract: 0.83\n",
      "Epoch:  0 | train loss: 0.0112 | test accuract: 0.82\n",
      "Epoch:  0 | train loss: 0.0398 | test accuract: 0.86\n",
      "Epoch:  0 | train loss: 0.8085 | test accuract: 0.88\n",
      "Epoch:  0 | train loss: 0.0041 | test accuract: 0.88\n",
      "Epoch:  0 | train loss: 2.3839 | test accuract: 0.88\n",
      "Epoch:  0 | train loss: 0.0048 | test accuract: 0.85\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.87\n",
      "Epoch:  0 | train loss: 0.0018 | test accuract: 0.88\n",
      "Epoch:  0 | train loss: 0.6119 | test accuract: 0.89\n",
      "Epoch:  0 | train loss: 0.0707 | test accuract: 0.87\n",
      "Epoch:  0 | train loss: 0.6956 | test accuract: 0.87\n",
      "Epoch:  0 | train loss: 0.0240 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0831 | test accuract: 0.89\n",
      "Epoch:  0 | train loss: 0.4113 | test accuract: 0.89\n",
      "Epoch:  0 | train loss: 0.0814 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.4609 | test accuract: 0.89\n",
      "Epoch:  0 | train loss: 0.0061 | test accuract: 0.87\n",
      "Epoch:  0 | train loss: 0.1854 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.0565 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.1091 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0752 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0488 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0119 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0029 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0141 | test accuract: 0.89\n",
      "Epoch:  0 | train loss: 0.0415 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0239 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.7345 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.3393 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.1468 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 1.2153 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0520 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.1853 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0096 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.3786 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.1598 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.0082 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.3034 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.4895 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.4923 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0013 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.6481 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.2787 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.2015 | test accuract: 0.90\n",
      "Epoch:  0 | train loss: 0.0123 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.0480 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.6994 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0031 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0018 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0099 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.3026 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0862 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.2738 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0348 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0974 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0357 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0603 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.91\n",
      "Epoch:  0 | train loss: 0.1902 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0021 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 5.1976 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 1.0590 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0232 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 1.0652 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1127 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1649 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.2852 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.1622 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0034 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0384 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0314 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0254 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0058 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0467 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0785 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1736 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0034 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0618 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0838 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0199 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0225 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 3.8251 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0030 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0048 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1412 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0070 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0390 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.1385 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 1.5934 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0242 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1346 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.1238 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0014 | test accuract: 0.92\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0065 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0351 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.93\n",
      "Epoch:  0 | train loss: 0.0130 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 2.1252 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0295 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.1237 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0760 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.1817 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0143 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0015 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0251 | test accuract: 0.94\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0510 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0062 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.2853 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0554 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0036 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0046 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.3072 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0038 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.5885 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0110 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0018 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0129 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0226 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0130 | test accuract: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0988 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0082 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0053 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.4775 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.6203 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0124 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0040 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0330 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0537 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0098 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0400 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.2236 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0914 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.2859 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0046 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1721 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0298 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0084 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0102 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.4283 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0058 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0092 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0113 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0087 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1574 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0036 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.2683 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0059 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0036 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0035 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1521 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0190 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0148 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 1.9416 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.5144 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0095 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2363 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0107 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0288 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0437 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0448 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0197 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0019 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0097 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 1.0439 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1145 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0026 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0016 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.6515 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.9194 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0028 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0133 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.3343 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1372 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0252 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1716 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0032 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0248 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0430 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0560 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0171 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0273 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0193 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0207 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0027 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0962 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0565 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0115 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 0.0015 | test accuract: 0.95\n",
      "Epoch:  0 | train loss: 10.4787 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.2040 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2653 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0057 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0023 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.8669 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0386 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0020 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.9387 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0014 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0237 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.7867 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0058 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0031 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0022 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0011 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0014 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0562 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0143 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.4098 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0585 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1374 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1565 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0571 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0049 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0183 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0294 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0013 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0081 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0122 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0197 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1061 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0028 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 4.0121 | test accuract: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0376 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.5852 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.3680 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0077 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0070 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0357 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2588 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0710 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0356 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0670 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0027 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2022 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0117 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0011 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0024 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0601 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0040 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0032 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0569 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0016 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2307 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0031 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0031 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0502 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0013 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0208 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1719 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 4.2414 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0148 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0016 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0614 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0062 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0018 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0045 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0025 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0044 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0131 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0352 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0153 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0023 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0023 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0078 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0753 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.3493 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1385 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0093 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0681 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0079 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0066 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 2.1784 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0029 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0356 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0047 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0033 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0077 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 3.6576 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.2666 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0046 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0373 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0035 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0022 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0013 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0464 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.1013 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0014 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0294 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0053 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0057 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0066 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0813 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0061 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0122 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0116 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0198 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0219 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0129 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0025 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0069 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0132 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.4299 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0092 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0148 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0109 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1745 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0133 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0040 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.4921 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0036 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0998 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0053 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0069 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.4352 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0064 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0966 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0016 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0130 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0169 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 8.3447 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0178 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0199 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0026 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0301 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 2.7001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0044 | test accuract: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0053 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0082 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0032 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.2588 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0293 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0016 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.8505 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0029 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0120 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0051 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0015 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0005 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0031 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.1801 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0597 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0051 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0073 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 1.7780 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0150 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0268 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0199 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0102 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0078 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.9799 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0046 | test accuract: 0.98\n",
      "Epoch:  0 | train loss: 0.0047 | test accuract: 0.98\n",
      "Epoch:  0 | train loss: 0.5268 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.3326 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 3.0804 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0045 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0169 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0045 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.3024 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 4.7014 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0040 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0070 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0029 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0248 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0261 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0057 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0058 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0084 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0011 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0698 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0419 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0026 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0145 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 3.5018 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 4.5895 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0057 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0044 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0035 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0032 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0028 | test accuract: 0.96\n",
      "Epoch:  0 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0069 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0043 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  0 | train loss: 0.0037 | test accuract: 0.97\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n",
      "processing epoch 1...\n",
      "Epoch:  1 | train loss: 0.0070 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1708 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0252 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0044 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 9.6177 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0024 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0181 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0273 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0037 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0038 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0062 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0078 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0133 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1895 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0499 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0166 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0267 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0180 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0298 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0040 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0359 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0052 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0013 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0029 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0314 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.8371 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1016 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0245 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0144 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0020 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0027 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1238 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0080 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0039 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0323 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0099 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0042 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0017 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0073 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 1.1233 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1199 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0022 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0400 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0264 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 5.8559 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0630 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0024 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0159 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0351 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0022 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0611 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0085 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0075 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0240 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0490 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 4.8486 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0112 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0020 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0089 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.7449 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.6321 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0026 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0111 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 3.1498 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0049 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0122 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0041 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0128 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.9041 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0027 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0032 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0092 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0014 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0027 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.3827 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0299 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0068 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0130 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0016 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0351 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1492 | test accuract: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 0.0064 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0028 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0205 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0051 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.1279 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0251 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0204 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0056 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0016 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.5056 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0181 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0036 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.5066 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0041 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0192 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0013 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0146 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0098 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0062 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.7655 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0998 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.2586 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.4448 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0438 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0091 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0185 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0013 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0076 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1113 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0153 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0007 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0086 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0779 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0031 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0034 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0007 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 9.9711 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0476 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0033 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0397 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0036 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0020 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.3818 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0016 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.6538 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0340 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0546 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0021 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0122 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.1095 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.1133 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0388 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1150 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0134 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0175 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0059 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0020 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0105 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0126 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0222 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0019 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 6.4509 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0308 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.2829 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0220 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0016 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0163 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0097 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.5445 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0112 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0037 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0768 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.4099 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0014 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1115 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0031 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0245 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0883 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0052 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0078 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0025 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0294 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.2743 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0038 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0073 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0162 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0373 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0383 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0021 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0024 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.3162 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.2461 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0772 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0160 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0232 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0032 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0057 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.5527 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0033 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0032 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 1.8724 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1061 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0659 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0176 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0007 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0100 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0718 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0104 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0013 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0146 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0115 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0229 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0237 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0088 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0104 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0113 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0630 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0265 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0070 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.5883 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0023 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.3532 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0503 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0033 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0025 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.2403 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1746 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0081 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0234 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 5.1035 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0029 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0092 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0258 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 1.2092 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0069 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0019 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.1954 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0021 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0044 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.4444 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0020 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0005 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0260 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0054 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0029 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0071 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 2.0534 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0057 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0037 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0054 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0075 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0014 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.6667 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0018 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.4149 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.1449 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 3.4562 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0039 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0155 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.5364 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 4.2623 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0242 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0012 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0040 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0011 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0089 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0182 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0105 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0009 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0013 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0027 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0042 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0008 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0160 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0098 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 1.0394 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 5.6502 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0010 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0015 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0056 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0092 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0006 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0002 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0003 | test accuract: 0.96\n",
      "Epoch:  1 | train loss: 0.0028 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0004 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0028 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0022 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0001 | test accuract: 0.98\n",
      "Epoch:  1 | train loss: 0.0000 | test accuract: 0.97\n",
      "Epoch:  1 | train loss: 0.0033 | test accuract: 0.97\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    print((\"processing epoch %d...\") % (epoch))\n",
    "    \n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        output = cnn(batch_x)\n",
    "        loss = loss_function(output, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(step % 100 == 0):\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = accuracy_score(pred_y, test_y.data.numpy())\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "            \n",
    "    test_output = cnn(test_x[:10])\n",
    "    pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze() #argmax\n",
    "    print(pred_y)\n",
    "    print(test_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-15.8691, -20.4210, -12.2617,  -8.8932, -20.5734, -19.7938, -30.4324,\n",
      "           1.2789, -12.8824, -11.3164],\n",
      "        [-16.5492, -19.1147,  -6.0860, -16.7400, -25.7764, -18.1991, -14.7787,\n",
      "         -40.4990, -16.4264, -28.7779],\n",
      "        [-11.9197,   1.1983,  -7.1548,  -9.1187,  -6.3031,  -9.5871, -11.0430,\n",
      "          -9.8213,  -7.8487, -10.5078],\n",
      "        [ -2.8273, -25.2429, -14.0327, -16.7457, -17.5488, -14.4820, -13.8328,\n",
      "         -20.1043, -16.3477, -13.0368],\n",
      "        [-13.5767, -22.1061, -15.8306, -12.7644,  -1.8660, -19.6274, -13.8663,\n",
      "         -13.5797, -14.8230,  -7.2967],\n",
      "        [-10.7551,   0.9979,  -6.7629,  -9.2626,  -5.9493, -11.3666, -12.5249,\n",
      "          -5.7081,  -7.2850,  -8.6097],\n",
      "        [-26.0220, -18.3382, -17.1139, -15.3935,  -3.7838, -15.6390, -25.2659,\n",
      "         -13.0112, -13.6627, -11.4186],\n",
      "        [-24.5699, -17.2270, -15.3113, -14.8903,  -8.5665, -10.0910, -20.8976,\n",
      "         -19.0979,  -9.2919,  -2.3492],\n",
      "        [-20.5367, -26.4240, -20.9178, -21.0867, -21.6919,  -3.4416,  -8.7864,\n",
      "         -24.2315, -13.6431, -15.3318],\n",
      "        [-20.4364, -28.6391, -21.4437, -15.0812, -11.3670, -17.7986, -31.6684,\n",
      "          -8.7451, -12.8823,  -4.3280]], grad_fn=<AddmmBackward>)\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "test_output = cnn(test_x[:10])\n",
    "print(test_output)\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y)\n",
    "print(test_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save parameters\n",
    "torch.save(cnn.state_dict(), \"../model/cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "# load parameters\n",
    "cnn.load_state_dict(torch.load(\"../model/cnn.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../data/stored_weights/'\n",
    "for name, w in cnn.named_parameters():\n",
    "    w_flat = torch.flatten(w).detach().numpy()\n",
    "    with open(save_path + str(name), 'w') as f:\n",
    "        for weight in w_flat:\n",
    "            f.write(str(weight) + ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
